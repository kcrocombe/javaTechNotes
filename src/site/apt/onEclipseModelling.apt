
Notes, in no particular order.


	will need a lot of tidying up

===


	Might try and format this up with 'Almost Plain Text' markup <APT>

	{{{./aboutThisDocumentation.html}About this Documentation}}

	{{Maven Notes}}

	{{{./gitNotes.html}Git Notes}}

	{{Some stuff on Oath2 and OpenID Connect}}

	{{Doxia}}

	{{GWT-Google Web Toolkit}}

	{{Technology Glossary}}

	{{Notes on Domain Driven Design}}

=================================

Bits and Pieces re eclipse

	[[1]] vrapper - a wrapper for vi

	Have installed this : seems to work ok. Gives the default edit vi-like propoerties.

=================================


	[[1]] Getting the implementation of a class to additionally implement an Interface not specifically modelled on the diagram

		add an @implement annotaion into the user-doc section of the generated java code:

---
	 /**
 	 	* <!-- begin-user-doc -->
		* An implementation of the model object '<em><b>My User Profile Mesg</b></em>'.
		*
		* @implements com.garmin.fit.UserProfileMesg NOT
		*
		* <!-- end-user-doc -->
		*/
---

		You can do likewise with @extends, ( although since the generated class always will extend the and a class can only extend a single Class) then this seems to be of limited value.

		I DO NOT THINK this ends up in the model files anywhere: I think it must be read from the java source files following regeneration - not absolutely sure on theis however.


		[[1]] Classes drawn upon the diagram are normally:

		a. implemented as an Interface
		b. supplied with a template \*.Impl Class that implements that interface

	This is a highly recommended Design Pattern.(See Effective Java).

	[[1]] It is possible to change the way that code is generated such that each Diagrammed Class is implemented as a class.

		open the \*.genmod file with the GenModel Editor

			Model --> Suppress Interfaces --> TRUE

	It seems that this will cause ALL modelled classes to be implemented as CLASSES. I have not found a way to allow just individual classes to be modelled as CLASSES: although I suspect is ought to be possible with some further clever annotations.


	[[1]] IF you put code snippets in your model they HAVE to be syntactically correct code ; otherwise the generation will bomb out!.


	[[1]] It is possible to sensibly represent External Interfaces ( i.e. interfaces supplied as part of the standard libraries, or third party libraries) on the diagrams. As long as these are marked as 'Interfaces', then the generator will not attempt any code generation for them, just the implementing/extending class.

	IF you DO put a external class on the diagram, the generated code:

		DOES NOT generate an INTERFACE for it.

		DOES create an Implementation class for it (BUT ITS BROKEN)
			The implementation
				extends the standard <MinimalEObjectImpl.Container> Class, and implements the ExternalClass. However classes can't implement OTHER classes ( so this fails). Nor can they extend more than 1 class, and since we are already extending the standard <MinimalEObjectImpl.Container> Class this isn't an option.

				( The <MinimalEObjectImpl.Container> Class is needed for other internal workings of the model).

				In other words, the construct can't work.

	IF you put an Internal Class on the Diagram, the generated code:

		* DOES create an INTERFACE for it. ( That extends the standard internal root object EObject)

		* DOES create a CLASS that implements the INTERFACE created. (It also extends the standard MinimalEObjectImpl.Container)

	IF you put an External Interface on the Diagram, the generated code:

		* DOES NOT create an INTERFACE for it  ( because it already exists somewhere)

		* DOES NOT create a CLASS for it.

	IF you put an Internal Interface on a Diagram, the generated code:

		* DOES create an INTERFACE for it. (That extends the standard internal root object EObject)

		* DOES NOT create a CLASS for it.


		[[1]] IF you DO want to use an external CLASS as part of the model, then you need to represent it:

		* as a Datatype. The advice seems to be that it is best to do this for only Simple types.

		* They can be indirectly represented by effectively creating a Wrapper Interface. At first sight, this
		approach seems to be fairly cumbersome. However it DOES represent a pretty solidly supported Design Pattern,
		namely: <Favouring Composition over Inheritance>

			Inheritance is a powerful way to archive code re-use, but it can lead to fragile software.

			Inheriting from ordinary classes across package boundaries is considered dangerous.

			(It is ok to use inheritance WITHIN a package though)

			It is OK to inherit from Abstract Classes : these should have been designed specifically for that purpose.

	It DOES require that a set of forwarding methods be written ( ie a method that basically just calls the method of the same name in the subOrdinate class).

	Can be used to LIMIT the functionality of the sub-ordinate class, by choosing to forward only certain methods.

	Can also use a Forwarding Class. This is useful if you have different object "inheriting" from your subOrdinate object.
	THe forwarding class is essentially re-useable.

	There is a choice to be made about whether the intance variable holdiung the subordinate Object should be private
	or public.

	If the subordinate Object is included in the Interface Definition, then essentailly all the methods on that
	subordinate object become visible

	If it is NOT then only the forwarding methods may be used to manipulate it, so you are effectively only exposing
	a subset of its properties.

		- Again this is a good thing. The more limited an objects properties are, the easier it is to test.


Delegating and Forwarding


		I have yet to find a way of sensibly using an actual concrete CLASS on the diagram that can be sensibly handled by the Code generator.

	[[1]] The graphical editor has a few Annoying Foibles:

		[[a]] If you amend stuff on the various Dialog boxes that pop up if you double click on an Item, then the changes do not take if you press 'OK' without moving out of the field you have just edited. You basically need to move the focus out of the edited field before pressing RETURN. Very Annoying.

		[[b]] If you give Instance Class Name to a Class/Interface (thereby turning it into a proxy for an external class), then if you change your mind, and try and delete it then it doesn't work too well. Even thouh the field is empty it treats it as being modelled by an external Null Class []. You need to use a different editor to correct this (edit the .ecore model file with the Ecore Editor).


	It is generally easier to refine items in the Ecore Editor once the basic Classes and Relationships have been
	modelled graphically.



	[[1]] Generating Failing with Unhandled Exceptions.

		Occasionally these occur during generation. I THINK it happens when you change the name of an entity and regenerate.

		It generally can be fixed by deleting the previously generated java files, HOWEVER be careful to save any custom code in these FIRST!



		[[1]] Some Documentation Stuff

	To see Documentation Boxes on the diagram editor, you need to have the documentation layer enabled.

	Documentation can be unattached ( ie. not associated with any particular element)

		- This makes its way into the .ecore Model file as a GenModel annotation of the Package with KEY = docuemntation and VALUES "Whatever documentation is".

		 NB - It seems you can only have ONE piece of unattached Documentation. However, it does not stop you creating another, in which case it OVERWRITES the previous one WITHOUT WARNING!.


	Documentation elements can be attached to the high level objects:
			Classes
			DataTypes
			Enumerations

	but not the lower level constructs ( operatios, attributes etc.)

		- These make their way into the .ecore Model file as a GenModel annotation of the Class/Enum/DataType, again with the KEY=documentation
		and VALUES "Whatever documentation is"

	Again if you attempt to create a SECOND note attached to a CLASS it will OVERWRITE the first WITHOUT warning!

	These get translated into the <!-- begin-model-doc-->   <!--end-model-doc --> section of the generated code

	( Note you can stick some annotations in here ( @extends, @inherits etc, so this is a potentially useful thing
	 to know about.)


	Documentation for attributes/operations can be specified as
		properties on the GUI modelling tool
			- THese get reflected as 'GenModel' Annotations in the .ecore model in the same way as Entities above..


	Note where snippets of code are entered: these do not form part of the .ecore file but as part of the .genModel file. Documentation
	of code snippets also ends up here.



	[[1]] The GenModel map is described by a URL
		http://www.eclipse.org/emf/2002/GenModel   ( which doesn't seem to exist as a browsable thing?)

		However it specifies what Key --> Value Mappings are valid for that GenModel Map.

		The key 'Documentation' is valid within the scheme ( with its value being whatever the documentation is).

		I don't know what other keys are legitimate.

		NB KEY is unique you can't have two element with the same key attached to the element.

		Nor can you make up arbitrary KEYS, they must be drawn from the domain specified by http://www.eclipse.org/emf/2002/GenModel.





		[[1]] Constructors and Factory Methods

	If you are running in the default configuration (Generating Interfaces and Implementing Classes), do not attempt to create explicit constructors on the diagram : in the context of a interface, they don't work.


	I feel there ought to be a way of getting the thing to generate more than just the default constructor...but if there is I haven't worked it out yet!

Backing out changes to Java Source.

	[[1]] The editor automatically keeps a history of all incarnations of source code files it generates. There is also a really good tool for comparing files in the History to the current file. It also supplies really good support for back porting any text changes that you might want to back out.



	[[1]] Representing Specific Generics, especially Collections, Lists etc

	The modelling tool seems to provide a limited range of generic collections:
		EEList<T>      --> org.eclipse.emf.common.util.Elist
		EMap <K,V>		--> java.util.Map
		ETreeIterator<T> --> org.eclipse.emf.common.util.TreeIterator

		If you want use a specific external class in your mode, the obvious way would seem to define an Datatype much as you would for other external Classes. However this does not seem to work too well.

		e.g.

		Name:						 IterableOfSomeClass
		Instance Class Name:  java.lang.Iterable
		Instance Type Name:   java.lang.Iterable<SomeOtherclass>

		This looks like it SHOULD work. However, in practise, this seems to get translated in the code to:
		Iterable<Object>
		and not
		Iterable<SomeOtherClass>


		However, it does seem to posssible to represent the required Collection as an Interface instead

		Name:						 IterableOfSomeClass
		Instance Class Name:  java.lang.Iterable
		Instance Type Name:   java.lang.Iterable<SomeOtherclass>

		Abstract: True
		Interface: True

		This DOES seem to get translated in the code as
		Iterable<SomeOtherClass>

=====




Eclipse Model Generator and JavaDoc.

	The generator will generate default javadoc for each class/attribute/operation in the interfaces (
	not much docuemntation seems to get auto-generted for the implemetation classes.

	Documentation stored in the .genModel file ( NOT the .ecore file) is what get populated the
	java doc. Although documentation in the .ecore file is not included directly, the tool does
	copy the .core documentation --> .genModel file by default ( if the equivalent .GenModel documentation
	does not already exist).

---
	<!---begin-model-doc -->
			Contains Documentation entered under:
					Properties --> Generation --> Documentation

	<!--end-model-doc -->
---

	Documentation within <!---begin-user-doc --> <!--end-user-doc --> Constructs does not get overwritten
	when the models are regenerated.


Generating the HTML

	* From eclipse
			Projects --> Generate Javadoc

	* From the command line
			$JDK_HOME/bin/javadoc


===


Wildfly Stuff

	New Installation downloaded ( wildfly-16.0.0 )

	As user wildfly:wildfly unzipped to /apps/wildfly-16.0.0

	As user kevin, tried to start it
			bin/standalone.sh

	..but threw various permissions errors

	Frigged various directories to try and get it started as a different user ( kevin ). This is so that I can start it up and shut it down from within Eclipse.

---
		chmod g+w standalone
		chmod g+w standalone/tmp
		chmod g+w standalon/configuration
		chmod g+r standalon/configuration/\*
		chmod g+r standalon/deployment
---

	Had to move existing deployment out out of the way.

---
		mv /apps/wildfly-16.0.0.Final/standalone/deployment /apps/wildfly-16.0.0.Final/standalone/deployment.old
---

	Instance would then start ok...

	Added 2 users: 1 Admin and 1 Normal as follows:

		Admin User:

---
	./add-user.sh

		a) Management User (mgmt-users.properties)

		Username : kevin
		What groups do you want this user to belong to? (Please enter a comma separated list, or leave blank for none)[  ]:
		About to add user 'kevin' for realm 'ManagementRealm'
		Added user 'kevin' to file '/apps/wildfly-16.0.0.Final/standalone/configuration/mgmt-users.properties'
		Added user 'kevin' to file '/apps/wildfly-16.0.0.Final/domain/configuration/mgmt-users.properties'
		Added user 'kevin' with groups  to file '/apps/wildfly-16.0.0.Final/standalone/configuration/mgmt-groups.properties'
		Added user 'kevin' with groups  to file '/apps/wildfly-16.0.0.Final/domain/configuration/mgmt-groups.properties'
		Is this new user going to be used for one AS process to connect to another AS process? No
---

		Normal User:

---
	./add-user.sh

		b) Application User (application-users.properties)
		Using realm 'ApplicationRealm' as discovered from the existing property files.
		Username : kevin
		What groups do you want this user to belong to? (Please enter a comma separated list, or leave blank for none)[  ]:
		About to add user 'kevin' for realm 'ApplicationRealm'
		Added user 'kevin' to file '/apps/wildfly-16.0.0.Final/standalone/configuration/application-users.properties'
		Added user 'kevin' to file '/apps/wildfly-16.0.0.Final/domain/configuration/application-users.properties'
		Added user 'kevin' with groups  to file '/apps/wildfly-16.0.0.Final/standalone/configuration/application-roles.properties'
		Added user 'kevin' with groups  to file '/apps/wildfly-16.0.0.Final/domain/configuration/application-roles.properties'
		Is this new user going to be used for one AS process to connect to another AS process? No.
---

		Once all the above was done, the Server could be at least started from eclipse.

 		...But not stop!. (Actually this is a bit of a red herring - eclipse reports that it has not stopped, but all the external signs are that it does.)


* Using Wildfly with Maven.

	Jboss (or possibly other third parties) provide a convneient plugin for use in Maven projects to help manage a server during the build and/or deployment processes.

	The plugin, <<wildfly-maven-plugin>>,  provides facilities to deploy/undeploy applications, start/stop webservers execute wildfly cli commands.

		example goals:

			* wildfly:deploy;

			* deploy:undeploy;

			* wildfly:startup;

			* wildfly:run (basically startup and deploy).


* Using a Maven Build archetype

	In order to provide a basic environment to evaluate and develop on from, built up an initial project based on a jboss/wildfly provided maven archetype.

	Note the version : v 8.2.0.Final

---
	mvn archetype:generate \
	-DgroupId=uk.co.pegortech.apps \
	-DartifactId=wildflyDemo2 \
	-DarchetypeArtifcactId=wildfly-javaee7-webapp-archetype:8.2.0.Final \
	-Dversion=1.0-SNAPSHOT \
	-DinteractiveMode=No
---
	Then build and run as follows:

---
	mvn package

	mvn wildfly:run
---

NB This seems to download and install its own versio of wildfly under target.???

	This build up quite an extended example encorporating
		Java Server Faces;
		JPA - Java Persistance Architecture
		EJB - Enterprise Java beans
		JAX-RS - Java API for Restful Web SERVICES



===========



{GWT-Google Web Toolkit}

	Documentation : {{http://www.gwtproject.org/}}

	Is a google provided SDK, providing a core set of Java API's and Widgets for the construction of browser-based UI.

	The name is possibly derived from the AWT classes used on thick-client java applications.

	It allows you to write AJAX applications in Java, and then compile them to JavaScript rather (than byte code). The JavaScript is downloaded by the browser and interpreted like javaScript anywhere.

	Can be used in any browser, including on mobile devices.


	AJAX - Ansyncronous JavaScript and XML  - is a set of web development techniques. ( Basically Web applications send and receive data asynchrounously ( in the background) without interfering with display or behaviour of the browser page.)  These days, JSON is used as much as XML.

	DOM - Document Object Model

	Serializable - allows the content of a dataobject to be moved out of a piece of running code and, either:
		a) Transmitted to another piece of running code
		b) Stored outside the application

	GWT uses RPC to transmit objects as parameters or Return Types, so they MUST be serializable.

	Deferred Binding - the compiler creates many versiojns of code at compile time: differnt versions for different browsers, different versions for different langauges. The appropriate version for a particular situation is determined at runtime.

	As well as the java objects, the SDK provides a number of tools to aid the development process.

		[[1]] The GWT developer plugin - this spans the gap between java byte code in the debugger and the JavaScript in the browser. This means you can effectively make c ode changes on the fly, and see them immediately reflected in the browser.

		[[1]] The GWT compiler - highly optimized compiler for converting java to javascript. Includes Speed Tracer for diagnosing performance problems in the browser.



=====

* Creating a GWT project with the Eclipse Plugin

	Can do this in 2 ways via the supplied Wizard. In each case, a starter direcory layout is created and populated with
	the bare minimum set of files:

		* a html page to launch the generated javaScript;

		* a css file to support cascading style;

		* Deployment Descriptor ( web.xml);

		* Example Client and Server Classes.

	The number and nature of files differs slightly depending whether you have chosen to create a Maven Project or not.

		* without Maven Support:

			* an External Dependency on the GWT SDK is configured

		* with Maven Support:

			* a pom.xml file is generated which referencoed the dependencies ion the SDK, but it does not down load those
			  to the local Maven Repositor at this stage.


			Had to  Change the Project Nature --> Maven

				Configure --> Convert to Maven Project

				( Little M appeared)

			Had to add in the www prefix...

			  <!DOCTYPE module PUBLIC "-//Google Inc.//DTD Google Web Toolkit 2.7.0//EN" "http://gwtproject.org/doctype/2.7.0/gwt-module.dtd">
		-->
			  <!DOCTYPE module PUBLIC "-//Google Inc.//DTD Google Web Toolkit 2.7.0//EN" "http://www.gwtproject.org/doctype/2.7.0/gwt-module.dtd">



		Creating a GWT project with a Maven Archetype

---
mvn archetype:generate \
	-DarchetypeGroupId=org.codehaus.mojo \
	-DarchetypeArtifactId=gwt-maven-plugin \
	-DarchetypeVersion=2.8.1 \
	-DgroupId=uk.co.pegortech \
	-DartifactId=mavenGwtProject \
	-Dversion=1.0-SNAPSHOT \
	-Dpackage=uk.co.pegortech.apps.mavenGwt \
	-Dmodule=Main \
	-DinteractiveMode=N
---

		This will generate the following basic files:

---
./pom.xml

./src/main/java/uk/co/pegortech/apps/mavenGwt/client/GreetingService.java
./src/main/java/uk/co/pegortech/apps/mavenGwt/client/Main.java
./src/main/java/uk/co/pegortech/apps/mavenGwt/client/Messages.java
./src/main/java/uk/co/pegortech/apps/mavenGwt/server/GreetingServiceImpl.java
./src/main/java/uk/co/pegortech/apps/mavenGwt/shared/FieldVerifier.java
./src/main/resources/uk/co/pegortech/apps/mavenGwt/client/Messages_fr.properties
./src/main/resources/uk/co/pegortech/apps/mavenGwt/Main.gwt.xml
./src/main/webapp/Main.css
./src/main/webapp/Main.html
./src/main/webapp/WEB-INF/web.xml

./src/test/java/uk/co/pegortech/apps/mavenGwt/client/GwtTestMain.java
./src/test/resources/uk/co/pegortech/apps/mavenGwt/MainJUnit.gwt.xml
---
		These are largely the same file that are generated using the GWT wizard from within eclipse.

---
Directories:
	./.settings  - Note: this is an empty directory.

Source Tree
	./src
	./src/main
	./src/main/java
	./src/main/java/uk
	./src/main/java/uk/co
	./src/main/java/uk/co/pegortech
	./src/main/java/uk/co/pegortech/apps
	./src/main/java/uk/co/pegortech/apps/mavenGwt
	./src/main/java/uk/co/pegortech/apps/mavenGwt/client
	./src/main/java/uk/co/pegortech/apps/mavenGwt/server
	./src/main/java/uk/co/pegortech/apps/mavenGwt/shared
	./src/main/resources
	./src/main/resources/uk
	./src/main/resources/uk/co
	./src/main/resources/uk/co/pegortech
	./src/main/resources/uk/co/pegortech/apps
	./src/main/resources/uk/co/pegortech/apps/mavenGwt
	./src/main/resources/uk/co/pegortech/apps/mavenGwt/client
	./src/main/webapp
	./src/main/webapp/WEB-INF

Testing Tree
	./src/test
	./src/test/java
	./src/test/java/uk
	./src/test/java/uk/co
	./src/test/java/uk/co/pegortech
	./src/test/java/uk/co/pegortech/apps
	./src/test/java/uk/co/pegortech/apps/mavenGwt
	./src/test/java/uk/co/pegortech/apps/mavenGwt/client
	./src/test/resources
	./src/test/resources/uk
	./src/test/resources/uk/co
	./src/test/resources/uk/co/pegortech
	./src/test/resources/uk/co/pegortech/apps
	./src/test/resources/uk/co/pegortech/apps/mavenGwt

Build Tree
	./target
	./target/generated-sources
	./target/generated-sources/gwt
	./target/generated-sources/gwt/uk
	./target/generated-sources/gwt/uk/co
	./target/generated-sources/gwt/uk/co/pegortech
	./target/generated-sources/gwt/uk/co/pegortech/apps
	./target/generated-sources/gwt/uk/co/pegortech/apps/mavenGwt
---
	It can be manipulated outside of Eclipse as follows:

---
mvn package    ( By default the gwt:compile goal is bound to the prepare-package phase)
---


	For full details, see the on-line documentation at:

	{{https://gwt-maven-plugin.github.io/gwt-maven-plugin}}


*	Importing into Eclipse.

		Use Import --> and select the Maven --> Existing Maven Project Wizard.

		This will create:

			.project    file

			.classpath  file

			.settings   filled with loads of config files


		A Warning will show against the Module Descriptor File  ( the .gwt.xml file), because it doesn't, by default include a schema Defininition line. This can be added in, as above:

---
<!DOCTYPE module PUBLIC "-//Google Inc.//DTD Google Web Toolkit 2.7.0//EN" "http://www.gwtproject.org/doctype/2.7.0/gwt-module.dtd">
---

		In the directory layout favoured by the gwt-maven-plugin archetype, the Module Description File is held within the resources directory of the tree. This differs from projects created directly through eclipse ( where it is held under the source tree).

		This can cause problems during Building if the Module Description File cannot be found. Normally, the resources dir DOES lie on the classpath normally searched during the Compilation.

		<<HOWEVER>> - the imported Maven Configuration Does seem to explicitly hide any files along the resources branch of the class path and so it cannot be found. In order to fix this, you need to amend the build path on the project so that these files are unhidden.

		Properties --> Java Build Path --> Source
			Amend the Excusion Filter on Both Resource Paths from \*\* --> \*.java

			( This will allow the .gwt.xml file to be found along the Classpath)


		Also, it is necessary to create a launch configuration for the imported applicaton. The gwt-maven-plug provides a specific goal for this.

		Use the gwt-maven-plugin to generate a Launch configuration for the application

---
mvn gwt:eclipse
---

		This will create a .launch post-fixed xml file. This can be imported into eclipse

			Import --> Run/Debug --> Launch Configurations


		This will create a Run Configuration based on the module name (e.g. Main.html) that will fire up the application in GWT Developemnt Mode ( i.e. using com.google.gwt.dev.DevMode as the main class, in super developemtn mode, and running the module (uk.co.pegortech.apps.mavenGwt.Main, for instance)

		Note that there is nothing provided to deploy the application proper to a webserver...


		The main goals of interest provided by the gwt-maven-plugin are:

---
mvn gwt:clean

gwt:compile

gwt:help

gwt:run
---


		Note that the compilation proper is tied into the prepare-package phase

---
mvn prepare-package
---


		For information, under the hood this is launching a shell script that basically runs:

			java -cp gwt-dev.jar com.google.gwt.dev.Compiler <module>



===

*	The Newer version of the GWT-Maven-plugin

	Although the org.codehaus.mojo version of the gwt-maven-plugin is what is configure by eclipse, this is now considered outdated. There is a new version that is now recommended for use in all projects:

---
groupID = net.ltgt.gwt.maven
<artifactId>gwt-maven-plugin</artifactId>
	<version>1.0-rc-10</version>
	<extensions>true</extensions>
---

	It theorettically provides better support for multi-module projects, and provides for a a much cleaner seperation of client side code ( i.e. the stuff that get compiles down to JavaScript), the backend webserver, and the classes that are shared between the two.


	The plugin itself is available at:

		{{https://tbroyer.github.io/gwt-maven-plugin/index.html}}


	Likewise, the archetypes used by the plugin have changed a fair bit from that used by the older plugin, most notably, the 3 sub-project created by default, and then a slightly different layout within each

	The archetype is created:

---
mvn archetype:generate \
		-DarchetypeGroupId=net.ltgt.gwt.archetypes \
		-DarchetypeVersion=LATEST \
		-DarchetypeArtifactId=<artifactId>
---

	where the available <artifactIds> are:

  	  * modular-webapp;

  	  * modular-requestfactory;

  	  * dagger-guice-rf-activities.

	(I haven't yet played with anything but the modular-webapp)

---
mvn archetype:generate \
	-DarchetypeGroupId=net.ltgt.gwt.archetypes \
	-DarchetypeVersion=LATEST \
	-DarchetypeArtifactId=modular-webapp \
	-DgroupId=uk.co.pegortech \
	-DartifactId=newGWTplugin \
	-Dversion=1.0-SNAPSHOT \
	-Dpackage=uk.co.pegortech.apps.newGWTplugin \
	-Dmodule=Module1 \
	-Dmodule-short-name=mod1 \
	-DinteractiveMode=N
---


	This creates a project with 3 sub-projects:

	test1-client:

		* contains the GWT client code, describing the UI ( ie. what gets transformed to JavaScript);

		* the \*.gwt.xml file describing the rentry point and various other things - need to understand this better I think

	test1-server:

		* contains the simple RemoteServiceServlet implementing the GreetingService interface (  GreetingServiceImpl.java );

		* misc css, xml, html files ( including web.xml and index.html).

	test1-shared:

		* contains the main Business Logic required by the app;

		* FieldVerifier Class;

		* GreetingResponse Class;

		* GreetingService Interface.


	This creates the same demonstration app that is bundled with the previous plugin archetype, but is code has been re-arranged for this new layout.


**	Test Compiling/Running/Debugging the Client Side code.

		The gwt modules, remember, eventually get compiled to JavaScript. However the AWT toolset provides a platform that will <emulate> the Javascript behaviour just by interpreting the .java files. This is quite nice, because once the various servers ( codeserver/webserver see below) are up and running, then all you need to do is save any change to the source file and refresh the browser in order to see your changes : you <don't need to compile the java at all>.

		The toolset provides 2 versions of this development platform (both Java Objects):

			CodeServer (com.google.gwt.dev.codeserver.CodeServer): This is what is preferred by the maven plugin. According to it documentation it is EXPERIMENTAL. I starts a code server in so called "Super Dev" Mode, a replacement for devmode that has the advantage of NOT requireing the use of Plugins in the browser to use it. However, it does not have support for authentication, data encryption etc.

			It also does not have a built-in Jetty.

			DevMode ( com.google.gwt.dev.DevMode): Running on this platform does not have Super Dev mode capablity and so will require a plugin inthe browser (GWT Developer Plugin) for it to run. It does, however, have an embedded webserver.

			( For completeness, the actual compiler is also a java object ( com.google.gwt.dev.Compiler )

		Each of these has a full set of command line options that might be specified ( documented both on the AWT site  {{http://gwt-plugins.github.io/documentation/index.html}} and available as good old JavaDoc)



		The recommended use of the plugin for development and debugging (at the command line) is to use the following plugin goals from the root POM:

			a. in one terminal window:

---
mvn gwt:codeserver -pl \*-client -am
---

				This invokes the <codeserver> goal on the plugin. The other arguments are <maveni> arguments:
					-pl is --projectList and so restricts the processing to just the 'client' sub-project,
					-am is --also-make, and so will pull in any dependencies from other projects ( in this case the "shared" sub-project.

				This will start up the codeserver java object, which will serve 'java object' when requested by a webserver.


		  b. in a second window fire up jetty:

---
mvn jetty:run -pl \*-server -am -Denv=dev
or
mvn tomcat7:run pl \*-server -am -Denv=dev
---
			<NB: the -Denv=dev is important!> This amends the profile active on the \*server build. The prod profile is active by default. Unless the dev profile is active, we won't get the proper interaction with the codeserver, and so java interpretationi doesn't happen.

			If you don't get the 'Compiling App'

			You can then point your web browser at the jetty/tomcat server

					by default : 127.0.0.1:8080/index.html   ( although the name of the initial page will vary per applicaiton)

			This will speak to the codeserver ( on 127.0.0.1:9876 )


		The gwt:codeserver goal invokes the execution of the maven lifecycle phase: process-classes.

		There are various options to control logging etc that can be added into the pom.xml as required.


		In theory, it should be possible to add options to the maven command line too.

			mvn awt:codeserver -DcodeserverArgs="-startupUrl /index.html"

		..although I've not managed to get that to work yet.


		There is full documentation of the plugin options on the plugin website, and help is available via the help goal:

			mvn gwt:help -Ddetail=true -Dgoal=<some-goal>


		It is usually a good idea to specify Mavens <<--ProjectList>> and <<--Also-make>> options in order to restrict compilation to just the '\*-client' project contain the AWT source.


		Note that it is also possible to use the gwt:devmode goal in order to compile/run gwt source. This fires up the GWT DevMode class with its build in webserver. However it does need a few more configuration steps:

			[[a]] It need the <startupUrl>/index.html</startupUrl> configuring into the pom.xml file.

			[[b]] It need the war:exploded goal running on the \*-server part of the application.

			[[c]] Make sure that the startupUrl is available along the public path of the module ( not sure what this is, but it is defined within \*.gwt.xml)

		However, even then, I have not been able to get this to reliably work!  Quite often, you just get a 404: Not found Error when looking for /index.html


* Running/Debugging Using the Eclipse Plugin

	A little misleadingly, the compile/debug/run functionality is available under:

			Right Click --> Debug as --> GWT Development Mode with Jetty			( basically gwt:devmode )
											 --> GWT Development Mode							( basically gwt:codeserver)
											 --> GWT Legacy Development Mode with Jetty

			Presumably, with a correctly configured maven, it would be possible to do a
					mvn jetty:run -pl \*-server -am -Denv=dev    or
					mvn tomcat7:run -pl \*-server -am -Denv=dev

			And in fact, this seems to work ok.

			Annoyingly, I have yet to find a way of configuring Maven to run:
			 		- a gwt:codeserver with the right parameters, or
					- a jetty:run with the right parameters

	With the Debug as running with Jetty, we can now right click on the URL within the 'Development Mode' Pane ( using the Jboss perspective). We can now launch the Chrome Browser with JavaScript Debug Support..

	Right clicking on the displayed page will allow us to inspect elements wetc to aid in laying out etc).



* Packaging.

		The Maven plugin provides 2 new packaging directive specifically for client-side GWT sources. These sit alongside alongside the usual ones ( war, jar, pom, era etc), and are specified in the pom for the sub-project in the usual way:

					<packaging>gwt-app</packaging>


			gwt-app : For client-side GWT code that will ONLY be compiled through to jacaScript via the GWT Compiler

			gwt-lib : For client-side GWT code that needs to be packaged in BOTH compiled and source form. Not sure what would need this, though??

		Note that shared code (i.e. \*-shared sub-project) is just a standard jar packaging, while the \*-server code is usually a war.



*	GWT Basics

		GWT code gets sent over a network in response to a user request, where it runs as JavaScript inside their browser.
		This put some restrictions on the Java libraries and code constructs that you can use in a AWT file.

		GWT modules are stored on a webserver as a set of JavaScript and related files. In order to run a module, it must be loaded from a web-page of some sort. Any HTML page can include a GWT application via a SCRIPT tag. This page is known as the HOST PAGE.

		Individual Units of GWT configuraion are called Modules. A module bundles all the configuration that a GWT project needs.

		Modules are defined in XML  ( \*.gwt.xml) and it is recomended that these are placed in the root package of the standard project layout. Typically the xml files will specify:

			* The Entry Point Classes. These are constructed WITHOUT parameters and are instantiated wheniever the module gets loaded. The classes onModuleLoad() method then get called.

			* Source Path. The module will specifiy which sub-packages also contain GWT source. Only these files are candidates for translation to JavaScript.

		Modules is one way that code is re-used within GWT: ie modules can act as libraries.

		Typically, a top-level XML definition will <include> all the libraries needed and then this will compile
		into a single set of JavaScript output.

		System Modules are provided to do things like:

			Provide unit test frameworks : JUnit.gwt.xml
			Provide JSON support: JSON.gwt.xml


		Entry Point classes implement the Entry Point Interface, which require just one method: onModuleLoad()
		Typically the onModuleLoad() method is used to:
				* create user interface components
				* setup event handlers attached to those components
				* modifiy the browser DOM ( Document Object Model)


		Useful:
			GWT.log("") can be used to flash debug messages while running in Development Mode ( They get optimised out
			when running Production Mode).



* Client Server Communication Basics

		* when the browser based code needt to interact with the server it makes an HTTP request using a Remote
		Procedure Call.

		* The RPC is then processed on the server.

		* Can use a variety of RPC mecanisms ( JSON, JSNI, or third parety)

		* Fundamental difference between AJAX apps and traditional HTML apps is that AJAX does not need to fetch new HTML pages while tey execute. ( On traditional HTML servers, the page is assembled (via JSP or similar) on the server and then sent and rendered ont eh browser: with AJAX the UI logic all happens on the browser). They just need to ship data.

		* It is <NOT> Simple Object Access Protocol (SOAP).


*	Creating Services

		To define your RPC interface, you need to:

			* Define a ServerSide interface for your Service that Extends RemoteService, and lists the required methods;

			* Define a ServerSide class to extend RemoteServiceServlet and implements the interface defined above;

			* Define a ClientSide synchronous interface to the service. However, this CANNOT be used directly by
			 the client ( AJAX - AYNCHRONOUS JavaScript and XML), so as well...

			* Define a Client Side asynchronous interface to the service, based on the above, that CAN then be called from the client side code.

		It is essential that the synchronous and asynchronous interfaces to conform to a NAMING standard: the compiler depends upon it.

				Synchronous Interface = Xxxxx

				Asynchronous Interface - XxxxxAsync

		They also NEED to have the same methods, except that the corresponding method in the Async interface will have an
		extra AsyncCallback<string> as its final parameter, e.g.

---
interface MyService {
	public void myMethod( String s);
}

and

interface MyServiceAsync {
	public void myMethod( String s, AsyncCallback<String> callback);
}
---

		They have to be in the same package.


		The Server side code which implements the services are based on the Servlet Architecture.

		The service implementation extends RemoteServiceServlet (which itself extends HttpServlet)
		and implements the sysncronous version of the interface.



		The process of making a call follows the same 3 steps:

			instantiate the service interface using factory method GWT.create() ( This is known
			as the service proxy)
			e.g.

				MyEmailServiceAsync emailService = (MyEmailServiceAsync) GWT.create(MyEmailService.class);

					Note: we create a instance of the class of the sync interface, and cast it to the async interface.

			Create an asynchronous callback object to handle the result

---
	AsyncCallback callback = new AsyncCallback() \{
  		public void onSuccess(Void result) \{ some stuff \}
  		public void onFailure(Throwable caught) \{ \}
  };
---

			Make the actual call:

---
  emailService.emptyMyInbox(fUsername, fPassword, callback);
---

			NB The service proxy can be created as an attribut in the EntryPoint Class, rather than recreating
			it in each method.


		Handling Exceptions

			RPC are open to all sorts of failures : Network failures, server crashes, slow performance etc.

			Important therefore to catchand handle these situations


		Server Calls are Asynchronous.

			Remember that calls to the server will NOT block. The lines of code immeditely following will execute.
			The onSuccess and andFailure Code will execute only when the callback completes.



		Some interesting features to be aware of:

			History : Typically applications run in a single page, so attemping to use the 'back' button to step back
			in the application does not work. There are features available to emulate this though.

			Internationalisation Support

			Scheduling Activity : Timers etc.

			JSON processing faciliites and Overlay Types

			Using Native JavaScript as well as generated Java Script


* Playing around creating interfaces.

**The Root Panel

	The Root Panel is essentially the base container for the dynamic elements in your application. It will be at the top of user interface hierachy.  It can be used in 2 ways:

		a) to generate the <entire> body of its host html page
		b) to generate specific <elements> within its host html page.

		In the parlance, teh Root panel either wraps the <\<body\>> element of the HTLM page or it can wrap any html element that you have given a specific id to.

	 		So, for example if you have a couple of table elements in a table row:

---
				\<tr\>
					\<td id="elementOne">\</td>
					\<td id="elementTwo">\</td>
				\<tr\>
---

		you would wrap those elements in code similar to:

---
			RootPanel.get("elementOne").set( addSomethingIn );
			RootPanel.get("elementTwo").set( addSomethingElseIn );
---

		A host page whose entire \<body\> element is to be wrapped would be considered:

---
			RootPanel.get().set( addSomethingElseIn );
---

		It is possibly for an html page to have more than one Root Page ( but I don't see how??).

		<NB. The Root Panel comes in at least 2 variant:  RootPanel and RootLayoutPanel>

		If you try laying things out in a RootPanel, then it will not work. In these circumstances you need to use the RootLayoutPanel version. <This took me a whole day to figure out!>


**The Host Page.

	Every application needs to be hosted from a bog-standar HTML file.

	The javascript file responsible for the dynamic content would normally be referenced as part of the html \<head\> element, which might also reference a style sheet to be used for the app (as a link in the below).

---
		<html>
			<head>
					...
					<script type="text/javascript" language="javascript" src="someJavaScript.nocache.js"></script>
					<link type="text/css" rel="stylesheet" href="someStyleSheet.css">
			</head>
---

		The dynamic content may be bound the entire body:

---
			<body></body>
---

		or bound to a particular data element with in the body:

---
			<body>
				<h1>Some Heading<h1>
				<div id="someDivision"></div>
				...
			</body>
---


=====

Getting Started with Spring.


	Created a new Eclipse Workspace for playing around with various Spring related stuff till I've
	reached a point where I am comfortable with it

		~kevin/eclipseSpringPlayground


	As ever, the first step seems to be creating a suitable directory structure to hold your project. There
	seem to be several ways of setting up a spring project, most of them variations on the same theme...

	a) By creating on from a Maven Archetype

			There are loads of them available in the various repositories, but the ones baring
			the org.springframework.boot GroupId are probably the ones to go for, since they are produced by
			Pivotal itself

			There are loads: most aligned to on or more Spring Modules ( Projects), and most of
			them boot projects of one form or another


			These can be built directly with maven:

---
mvn archetype:generate \
   -DarchetypeGroupId=org.springframework.boot \
   -DarchetypeVersion=LATEST \
   -DarchetypeArtifactId=spring-boot-sample-jetty-archetype \
   -DgroupId=uk.co.pegortech.apps \
   -DartifactId=sampleProject2 \
   -Dversion=1.0-SNAPSHOT \
   -Dpackage=uk.co.pegortech.apps.sampleProject2 \
   -DinteractiveMode=N
---


			Central to these are the inclusion of:

---
spring-boot-maven-plugin
---

			and the following dependencies

---
spring-boot-starter
spring-boot-starter-jetty
spring-webmvc
spring-boot-starter-test
---

			Most of the Compiling/Linking is provided by default by Maven via ists usual lifecycles phases

---
mvn clean
mvn package
mvn validate
---

			The one goal of interest provided by the spring-boot-maven-plugin

					mvn spring-boot:run    ( which kicks off the Spring Boot Container and serves the app)


		b) This can be done in the same way through Maven in Eclipse

			File --> New --> Other --> Maven --: Maven Project

			You then get a wizard that you can use to select the same artifact as above.

			They build by invokoking the same Maven goals

			There is a specific 'Run as Spring boot app' to invoke the spring-boot:run goal.


		c) Spring itself provides an online Spring Initializr in order to get you kickstarted with a prokject strucure.

			This is available via

					{{http://start.spring.io}}

			and is a little gui that will let you choose all the spring dependencies you need.

			This downloads as a zip file

			When unzipped you can build and run as before

				mvn verify

				mvn spring-boot:run


		d) IF you really want to you can fetch the starter strucure via curl.

				curl https://start.spring.io/starter.tgz -d style=web -d name=simple | tar -xzvf -



		e) The Spring Initailiser is also, and most conveniently available through the Spring Plugin for
			Eclipse

				File --> New --> Other --> Spring Boot --> Spring Starter Project

			This fires up a wizard that lets you choose all the available spring dependencies based
			on the problem at in hand.

			A proper Maven Project is then created nicely within eclipse.

			THIS IS THE METHOD OF CHOICE I THINK.

		f) It is alos possible to create a template using the spring commad shell ( if it is
		installed)

				spring init

		This will download a demo.zip file from spring.io, and it can be unzipped and used. Other dependendencies
		c an be added in by specifying various -D options.

	Of particulare usefulness is a little wizard that will help you build all of the 'Getting Started Guides'.
	This looks really useful and will look at this furhter shortly.

=====

Notes on Spring Boot

	At the moment I have 2 information sources dedicated to Spring Boot:
		Spring Boot in Action : is OK
		Spring Boot Reference Guide ( i.e. th official Documentation) : is Better. As long as you are reasonably comfortable with Spring Concepts then this is pretty good.


	Installed the Spring Boot CLI

		brew tap pivotal/tap

		brew install springboot

		spring --version

			==> 2.1.4.release



* What is Spring Boot?

 	Have been struggling to understand exactly what spring boot is.   It does not necessarily seem to be the natural starting point for learning boot.  Although I think it is indended to get a project up and running with spring quickly, it doesn't really teach too many principles : you probably need to take a step back and read some non-boot materail on Spring generally until you understand what it is is doing with stuff like;

		* Dependency Injection;

		* annotations;

		* Bean and Containers;

		* Wiring via XML, Java or auto;

		* Aspects

	Only once you have understood all that will SpringBoot make any sense.

	When you do however, this is what Spring Boot specifically brings:

		- Starter Dependencies.  Basically boot provides a whole bunch of maven/gradle artifcacts that make it easier
		to pull together the various jars/libraries that yyou might need to support a particular type of projects

		Firstly there is a definitive Parent Maven POM : spring-boot-starter-parent

		If you remember, properties in a maven pom tree get inherited from their parent (if they are not over-ridden). By
		inheriting from this you get a solid maven configuration starting point. spring-boot-starter-parent itself
		inherits as follows:

				spring-boot-build
					--> spring-boot-dependencies
							--> spring-boot-starter-parent

		A major advantage of this is that the items making up this list have been heavily curated by Spring: they are collections
		whose particular versions are know to work together.

		Consequently,

				YOU DO NOT NORMALLY NEED TO SPECIFY THE VERION OF AN ARTIFACT THAT YOU WANT TO INCLUDE IN YOUR PROJECT. IT
				WILL INHERIT THE VERSION KNOWN TO WORK FROM THE SPRING PARENT POM.

		It also brings in and configures the appropriate plugins to work the more usual build processes:

			* e.g. compiling;

			* running tests;

			* buildings jars/wars etc.;

			* deploying to webservers etc.

		Most of these are just bog-standard third party plugins commonly used in java development generally.
		However Spring Boot does provide one custom plugin:

			spring-boot-maven-plugin

		This will package your application as an executable jar.  One of the dependencies pulled into the -starter- Configurations is an embedded tomcat server ( see below).

		Consequently the packaged jar does not have to be run inside a webserver: it can be just run from the command
		line:

				java -jar <someSpringJar>

		The maven plugin can also be used to do the same thing using the spring-boot:run goals

				mvn spring-boot:run


		So it basically gives you a decent lifecycle.


		Secondly it provides a whole set of starter dependency sets to work with.

		These are all available from the maven/gradle repositories and generally have a name

				spring-boot-starter-<something>

		These are just collections of dependencies ( jars/libraries) that commonly get used together.

		For example the spring-boot-starter-web dependency collects together:

    	* org.springframework.boot:spring-boot-starter:jar:2.1.4.RELEASE:compile;

    	* org.springframework.boot:spring-boot-starter-json:jar:2.1.4.RELEASE:compile;

    	* org.springframework.boot:spring-boot-starter-tomcat:jar:2.1.4.RELEASE:compile;

    	* org.hibernate.validator:hibernate-validator:jar:6.0.16.Final:compile;

    	* org.springframework:spring-web:jar:5.1.6.RELEASE:compile;

    	* org.springframework:spring-webmvc:jar:5.1.6.RELEASE:compile;


		Each of these has its OWN dependecies which are then pulled in using Maven transitive dependency processing

		You can see the full expnaded list of stuff that will be pulled in Using

---
			mvn dependency:tree

				[INFO] \- org.springframework.boot:spring-boot-starter-web:jar:2.1.4.RELEASE:compile
				[INFO]    +- org.springframework.boot:spring-boot-starter:jar:2.1.4.RELEASE:compile
				[INFO]    |  +- org.springframework.boot:spring-boot:jar:2.1.4.RELEASE:compile
				[INFO]    |  +- org.springframework.boot:spring-boot-autoconfigure:jar:2.1.4.RELEASE:compile
				[INFO]    |  +- org.springframework.boot:spring-boot-starter-logging:jar:2.1.4.RELEASE:compile
				[INFO]    |  |  +- ch.qos.logback:logback-classic:jar:1.2.3:compile
				[INFO]    |  |  |  +- ch.qos.logback:logback-core:jar:1.2.3:compile
				[INFO]    |  |  |  \- org.slf4j:slf4j-api:jar:1.7.26:compile
				[INFO]    |  |  +- org.apache.logging.log4j:log4j-to-slf4j:jar:2.11.2:compile
				[INFO]    |  |  |  \- org.apache.logging.log4j:log4j-api:jar:2.11.2:compile
				[INFO]    |  |  \- org.slf4j:jul-to-slf4j:jar:1.7.26:compile
				[INFO]    |  +- javax.annotation:javax.annotation-api:jar:1.3.2:compile
				[INFO]    |  +- org.springframework:spring-core:jar:5.1.6.RELEASE:compile
				[INFO]    |  |  \- org.springframework:spring-jcl:jar:5.1.6.RELEASE:compile
				[INFO]    |  \- org.yaml:snakeyaml:jar:1.23:runtime
				[INFO]    +- org.springframework.boot:spring-boot-starter-json:jar:2.1.4.RELEASE:compile
				[INFO]    |  +- com.fasterxml.jackson.core:jackson-databind:jar:2.9.8:compile
				[INFO]    |  |  +- com.fasterxml.jackson.core:jackson-annotations:jar:2.9.0:compile
				[INFO]    |  |  \- com.fasterxml.jackson.core:jackson-core:jar:2.9.8:compile
				[INFO]    |  +- com.fasterxml.jackson.datatype:jackson-datatype-jdk8:jar:2.9.8:compile
				[INFO]    |  +- com.fasterxml.jackson.datatype:jackson-datatype-jsr310:jar:2.9.8:compile
				[INFO]    |  \- com.fasterxml.jackson.module:jackson-module-parameter-names:jar:2.9.8:compile
				[INFO]    +- org.springframework.boot:spring-boot-starter-tomcat:jar:2.1.4.RELEASE:compile
				[INFO]    |  +- org.apache.tomcat.embed:tomcat-embed-core:jar:9.0.17:compile
				[INFO]    |  +- org.apache.tomcat.embed:tomcat-embed-el:jar:9.0.17:compile
				[INFO]    |  \- org.apache.tomcat.embed:tomcat-embed-websocket:jar:9.0.17:compile
				[INFO]    +- org.hibernate.validator:hibernate-validator:jar:6.0.16.Final:compile
				[INFO]    |  +- javax.validation:validation-api:jar:2.0.1.Final:compile
				[INFO]    |  +- org.jboss.logging:jboss-logging:jar:3.3.2.Final:compile
				[INFO]    |  \- com.fasterxml:classmate:jar:1.4.0:compile
				[INFO]    +- org.springframework:spring-web:jar:5.1.6.RELEASE:compile
				[INFO]    |  \- org.springframework:spring-beans:jar:5.1.6.RELEASE:compile
				[INFO]    \- org.springframework:spring-webmvc:jar:5.1.6.RELEASE:compile
				[INFO]       +- org.springframework:spring-aop:jar:5.1.6.RELEASE:compile
				[INFO]       +- org.springframework:spring-context:jar:5.1.6.RELEASE:compile
				[INFO]       \- org.springframework:spring-expression:jar:5.1.6.RELEASE:compile
---


				The Boot Reference Manual gives a good indication of what -starter- to use in any given situation.


				If you need to exclude something that wouyld be brought in automatically by any of this, then you
				can specify this in your Maven Configuration

				e.g.

---
					<dependency>
						<groupId>org.springframework.boot</groupId>
						<artifactId>spring-boot-starter-web</artifactId>
						<exclusions>
							<exclusion>
								<groupId>com.fasterxml.jackson.core</groupId>
							</exclusion>
						</exclusions>
					</dependency>
---



		Configuration CLASSES
			Spring favours JAVA-based Configurarion

			It is generally recomended that a single Configuration Class be used.

			Often the class that defines the main() method is a good place as the primary
			@Configuration class. This can be used to import other configuration CLASSES
			as needed.




		AutoConfiguration

			This is an attempt by SpringBoot to cut down the amount of configuration a projects needs. Typically, non-boot Projects
			can need a lot of configuration : either in XML or Java.

			Spring-Boot auto-configuration is a runtime process ( more accurately, at application startup)

			It is based on the jar dependencies that have been configured. Basically Spring-Boot will scan the class Path
			and try to define and configure any beans it thinks it might need.

			YOU NEED TO OPT INTO AUTO CONFIGURATION - IT DOES NOT HAPPEN BY default:

				You do this with either of these annotations:
					@EnableAutoConfiguraton
					@SpringBootApplication ( which includes the @EnableAutoConfiguration)

			There is a JAR file called spring-boot-autoconfigure that contains several other configuraiton classes. When
			autoconfigure is enabled, any or all of these will contribute to the auto-configuration.

			Note that configuration is CONDITIONAL - basically configuration can be available in an applicaiton but
			not applied unless certain conditions are met. Usually these conditions are expressed as @annotations
			in the usual Spring way.

			Most of the AutoConfiguration constructs use the @ConditionalOnMissingBean annotation. This means they ONLY
			get used when a Bean has NOT already been configured.

			TO FIND OUT WHAT AUTO-CONFIGURATION IS BEING APPLIED AND WHY, START THE APP WITH THE
			--DEBUG switch

				This will list out a report e.g.

---
				============================
				CONDITIONS EVALUATION REPORT
				============================


				Positive matches:
				-----------------

 			CodecsAutoConfiguration matched:
				- @ConditionalOnClass found required class 'org.springframework.http.codec.CodecConfigurer' (OnClassCondition)

 			CodecsAutoConfiguration.JacksonCodecConfiguration matched:
				- @ConditionalOnClass found required class 'com.fasterxml.jackson.databind.ObjectMapper' (OnClassCondition)

 			CodecsAutoConfiguration.JacksonCodecConfiguration#jacksonCodecCustomizer matched:
				- @ConditionalOnBean (types: com.fasterxml.jackson.databind.ObjectMapper; SearchStrategy: all) found bean 'jacksonObjectMapper' (OnBeanCondition)

			...
---


			These do tend to be quite lengthy.


		Note that if you manually start to add configuration then that part of the auto configuration will no
		longer be applied

		Specific auto-configurations can be disaled by using the exclude attribute on the @EnableAutoConfiguraton annotations

		Note: Configuration Classes are just classes, and are documented with javadoc in the usual way.



		IT is also possibly to tweak the behaviour of autoconfigured beans without supplying your own version: you can do THIS
		by configuring particular application properties. Spring has a list of about 300 properties that can be amended/adjusted as
		required. This can happen in a number of places, in order of precedence:

			1 Command-line arguments
			2 JNDI attributes from java:comp/env
			3 JVM system properties
			4 Operating system environment variables
			5 Randomly generated values for properties prefixed with "random.\*" (referenced when setting other properties, such as ${random.long})
			6 An application.properties or application.yml file outside of the application
			7 An application.properties or application.yml file packaged inside of the application
			8 Property sources specified by @PropertySource
			9 Default properties

		The application.propertied or applicaiton.yml files can sit in several places:
			1 Externally, in a /config subdirectory of the directory from which the application is run
			2 Externally, in the directory from which the application is run
			3 Internally, in a package named config
			4 Internally, at the root of the classpath


*Spring Boot features

			SpringApplication Class.

				- is a convenient way to bootstrap a Spring web application that is started from a main() method.
				- It has a simple static method SpringApplication.run(Class, String), which you just use to pass your application class and any command line paramters you would liek to use.

---
	public class Application {

  	public static void main(String[] args) {
      SpringApplication.run(Application.class, args);
    }
	}
---
 			It creates a suitable Spring ApplicationContext, loads all the singletonm beans, and makes commandline paramters available.

			If you need to customise how your application needs to run, just create an instance of the SpringApplication class, tweak it as required, then invoke the run method.

			i.e. to get rid of banners etc...

---
	public static void main(String[] args) {
		SpringApplication app = new SpringApplication(MySpringConfiguration.class);
		app.setBannerMode(Banner.Mode.OFF);
		app.run(args);
	}
---

			For more complicated situations, you can use a Builder Class to generate ones

---
	new SpringApplicationBuilder()
			.sources(Parent.class)
			.child(Application.class)
			.bannerMode(Banner.Mode.OFF)
			.run(args);
---

			If you need to access command line arguments within your application, inject a ApplicationArguments bean. This will be wired in

				e.g.

---
	public class MyBean {

		public MyBean(ApplicationArguments args) {
			boolean debug = args.containsOption("debug");
			List<String> files = args.getNonOptionArgs();
			// if run with "--debug logfile.txt" debug=true, files=["logfile.txt"]
		}
	}
---


			If you need to run some application code once the applicaiton has started, you can implement the ApplicationLineRunner or CommandLineRunner interfaces:

				e.g.

---
	public class MyBean implements CommandLineRunner {
		public void run(String... args) {
			// Do something...
		}
	}
---

			Likewise if you need to execute something at shutdown , or return specific codes, etc that is all possible.


* The Spring Command Line INTERFACE

	Spring boot has an optional Command Line Interface that you can download and install. It is essentailly a shell like environment. Once entered, you can actually run stuff interactively; although it not likely to be used this way.

				spring shell

	More usually it would be used to run scripts: it is an interpreter of Groovy syntax

	Consequently you can write scripts, store them in the file system, and have the CLI run them:

				spring run ./someGroovyFile.Groovy

	There is command line help Available

				spring --help


* The Spring Actuator

	An actuator is a manufacturing term that refers to a mechanical device for moveing or controlling something.

	Adding the actuator to a spring application exposes a set of endpoints that let youi monitor and interact with your application. Each moay be sepeprately enabled or disabled.

	To add an actuator to a Maven Project add the Dependency

---
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-actuator</artifactId>
		</dependency>
---

	There are a whole load of things that can be examined
		- auditevents
		- beans ( a complete list of bean in the app)
		- conditions that were evaluated on configuration/auto configuration and why or not they matched
		- health
		- request Mappings
		- shutdown swith

	Endpoints are exposed either via HTTP or JMX. Usually it is HTTP and the endpoint is exposed along /actuator/health
	(for the health endoint).

Standard Spring Techniques with Spring Boot

	- ComponetScan
	- Autowiring


	@SpringBootApplication is equivalent to
		@EnableAutoConfiguraton
		@ComponentScan
		@Configuration



	The Spring-boot-devtools package is *not required* for spring boot, but provides some features that may be useful in a develoepmtn settings

* Deployment options.

	Out of the box, SpringBoot is built as a standard jar file, with an embedded tomcat server. Consequently it
	runs just as a standard jars

			java -jar <applicaton.jar>

	This is known as a FAT jar - basically it contains ALL the jar files needed by the app ( including, in this case, the application server)

	To prefer Jetty,

		add an exclusion to you maven files

-----
			<dependency>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-starter-web</artifactId>
				<exclusions>
					<exclusion>
						<groupId>org.springframework.boot</groupId>
						<artifactId>spring-boot-starter-tomcat</artifactId>
					</exclusion>
				</exclusions>
			</dependency>
-----

		...and add in the jetty servers

-----
			<dependency>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-starter-jetty</artifactId>
			</dependency>
-----

  IF you are deploying to an existing webserver ( tomcat, wildfly etc....)
	 a. Change from a jar packaging to a war Packaging in the pom.xml
	 b. Remove or comment out the spring-boot-maven-plugin in the pom.xml
	 c. Add a web entry point to your application. This is done by making the Application class ( or whatever it might be called), extend the SpringBootServletInitializer and override its configure() method

---
			@Configuration
			@ComponentScan
			@EnableAutoConfiguration

			public class Application extends <SpringBootServletInitializer> {

 				private static Class\<Application> applicationClass = Application.class;

 				public static void main(String[] args) {
		 			SpringApplication.run(applicationClass, args);
 				}

 				@Override
	 			protected SpringApplicationBuilder <configure>(SpringApplicationBuilder application) {
			 		return application.sources(applicationClass);
	 			}
		}
---


Cloud deployment.

	How this is deployed will vary depending on the facilities provided by the particular provider:

	Many require you to bring your own container : so the fat jar is ok for them, albeit wrapped in some way to make it fit on the platfoem in question e.g.

		CloudFoundry (an openSource Technology) implemenations employ a buildpack approach : the build pack wraps the jars

		Heroku (SalesForce) employs something similar similar

	Quite like the idea of Deploying to a standard implementation: at the moment this ties me to IBM or Pivotal (see below)




====
====

Working through some 'Getting Started Guides'

	Have picked out a series of Spring Boot starter projects to work through (from the spring.io site). Basically I am going to build these up in turn, and comment them, as heavily as I need to ensure that I understand whats going on. I may in fact try to customize some of them as I go in an attempt to learn something or make them more interesting. If so I'l comment below.

	Note: these are all held withing the eclipseSpringPlayground workspace.

	Most of these profect have gradle bits and pieces in them too, but I removed all that before working the project.



	1. ags1-spring-boot : Building an Application with Spring Boot

		A simple 2 class web application using Restful API, and absolutely no HTML element, but still demonstrates lots of useful stuff about Spring. I've heavily documented it to:

		* explain what @SpringBootApplication annotation actually does : i.e. its composite nature, and what its component annotations do: @Configuration, @EnableAutoConfiguration, @ComponentScan, @Component;

		* What is happening when you configure a Maven POM.XMl to use SpringBoot;

		* explain how SpringBoot uses the classpath in its AutoConfiguration;

		* usage of the SpringApplication class to bootstrap a Tomcat embedded webservers and how to configure the startup process, including how to run bits of code on startup;

		* How to query the ApplicationContext;

		* Creation and autowiring of a very simple bean;

		* Explain what the @RestController annotation does, and how that implies @ResponseBody and how that routes the return output of the methods of the class it is applied to (i.e. via MessageConverters);

		* Explains how the @RequestMapping annotation causes the Dispatcher to route Requests to methods to handle them;

		* Illustrate that @RequestMappping functions can take arguments widely varied in both NUMBER and TYPE;

		* Likewise illustrates the return values of @RequestMappping functions can be vary in TYPE and INTERPRETATION;

		* It also explains what the impliedd @EnableMvc behaviour and hints at how a webMvc configuratoin may be customised;

		* Demonstrates the Actuator feature and shows how it can be used to get useful information out of a running application;

		* Shows use of a properties file to reconfigure the behaviour of the actuator and expose its endpoint on HTTP rather than JMX;

		* explain what the Junit @Runwith() annotation does;

		* explain what @SpringBootTest does, esp how it leads to the configuration of either a real or Mock webserver for Testing;

		* explains what the MockMvc class is and how to perform() tests with it;

		* draws attention to the useful MockMvcResultMatchers Class;

		* discusses how to set up and run unit tests with maven;

		* discusses how to set up a Real Webserver for Integration Testing;

		* discusses how to run Integration Tests with Maven;


		1.	ags2-serving-web-content : Serving Web Content with Spring MVC

		This is another springBoot application, and again is up an running with minimal configuration. It exhibits much of the characteristics of the previous demo app, and has a few features of note of its own:

		* Shows a variation on the way the SpringApplication can be fired up in order to provide custom Banner;

		* Illustrates the use of the Logger Interface (and Apache log4j class) in order to write output to the console;

		* Demonstrates the use of a @Bean creation method with the Application @Configuration, and the injection of a Logger Bean into the Greeting RestController both via Constructor injection and Field Injection;

		* How we can make the variable injected to be final ( Good Practice);

		* How we can instead create our own implementation of Logger, annotate it as a @component and have the framework inject it;

		* The @GetMapping as a specialisation of the @RequestMapping in mapping URL to functions;

		* Pattern matching on Paths Mapped;

		* Capturing segments of the URL as @PathVariables;

		* Use of @GetMapping at method and controller class level;

		* use of @RequestParam to binf explicit parameters given on the URL to method parameters;

		* introduction of the Model interface to capture the data elements to be rendered in the HtmlResponse;

		* using the Logger mechanism to display the elements in the model to the console;

		* The method return value as the nem of the View to render the model;

		* The templating sub-system Thymeleaf, and how it is wired into SPRING;

		* The functioning of the View and ViewResolver Interfaces ( See notes elsewhere with regard to Thymeleaf);





Thymeleaf Templating System

	[[1]] M Thymeleaf is a HTML based templating system that has specific support in Spring.

	 * Firstly, Standard HTML5 documents are created either manually, or with tool support.

	 * Secondly, specific HTML5 elements are then further annotated with Thymeleaf specific tags.

	 * These tags have no meaning to a browser, so the tagged up HTML can be viewed in a browser as though the thymeleaf tags were not there.

	 * The thymeleaf tags essentially allow you to work more effectivley with the model data that will eventually sit inside the page: be it formatting, support for selection and iteration, data capture etc.

	 * The thymeleaf marked up .html file is loaded up with data from the Model and rendered.


Options for Web hosting

	- Google App Engine

			{{https://cloud.google.com/appengine/docs}}

			{{https://cloud.google.com/products/}}

			Offerings:
				- Compute  basically a virtual linux box

				-	App Engine  Provides various Application Environments /  Frameworks for hosting application services ( app services, databases etc ). Seems to imply there is a free quota before charges start being applied. Might be worth looking at.

				- Cloud Datastore  NoSql storage
				- Cloud SQL  relation db Mysql
				- Cloud Storage  object storage

				AppEngine   Appear to be 4 standard offering
					Python  ( with webapp2 and Jinja2 frameworks )
					Java  (with maven )
					PHP ( with Cloud SQL )
					GO

					In order to remain chargeless, needs to use the noSql datastore. ( BigTable ??) SQL databases will incur charges. ( Dont think MongoDb will ).


		- OpenShift  possibly an option ( seems to be the Red Hat option )

		- Amazon Web Services -  There are decent options free for a year. But then it gets quite complicated...

		- Heroku - (SalesForce company) looks quite Good. Free Optionm that sleeps after 30 mins, plus a cheap hobby setting where you only pay for when the application is running ( if ran continuously it would cost $7 a month.) Will need to pay for database too ( postGres)

		- Google Cloud

		- CloudFoundry providers: this is an openSource system. Some Providers
			- Pivotal - Offers $80 of credit, and then pay-as-you use (about $20 per month)
			- IBM





=======

Redhat OpenShift

	Created a new account kevin.crocombe@blueyonder.co.uk in order to play around.

		{{https://console.starter-us-east-1.openshift.com/console}}

	This, I think, uses an OpenConnect ID in order to logon. If no active session is in progress, the user will be re-directed to a login page.

	It is possible to login either:
			via login id ( kcrocombe)
			via email address ( kevin.crocombe@blueyonder.co.uk)

	Once logged in a OpenConnect ID toke will be issued, which can be used to give access to a command line session via oc (sess below).


	Communicate with the platform via either:

		A command line interface : the <oc tool>

		The web console - available of te redhat platform itself.

	Both methods comminicate with RH via the same REST API

 		{{https://docs.openshift.org/latest/rest_api/index.html}}

	There are alsop plugins for various IDE's including eclipse:

		{{https://tools.jboss.org/features/openshift.html}}


	 The underlying orchestration system is <Kubernetes>, which RedHat have enhanced in a few areas.

	 Is a <container> application platform.

	 		oc login


	 Easiest way to deploy an application is to use a Docker-Formated Image

* Some Terminology

	 <Container Image> : a container image is a standard unit of software, that packages up all its code, libraries and dependencies so that the application can run quickly and reliably from one computer environment to another. Container Images, in essence, are just files, so may be held in <Repositories> for deployment, much like any other file.

	 <Docker Container Image> : is such a particular type of container image : namely one intended to run on the <Docker> platform. Docker images are lightweight, standalone, executable packages. They include code, libraries, system tools, setting. They are in essence virtual software environments.

	 <Container> : Container images become containers at runtime i.e. when they become assosiated with a platform to support them. Docker Container Images become Docker Containers when they run on a Docker Platform. Different  Containers may communicate between themselves via well-defined channels.

	 <Docker Engine> : is a software product, produced by Docker, that provides OS-level virtualisation : i.e. in whcih the kernel allows the existence of multiple isolated user-space instances. These instances called Containers by Docker, but variously refered to as Zones, Partitions, Virtual Environements in other implementations, look like real computers from the point of view of the software running inside them.

	 Docker runs all containers on a single operating system. This makes them more lightweight than full virtual servers (which also have a virtualised os running in the image.)

	 <Kubernetes> (Greek for "governor") is an open source container <orchestration system> : it automates application deployment, configuration. scaling and management. It was originally designed by Google. It works with a wide range of container tools, including Docker. Many cloud services now offer Kubernetes-based platforms, and many vendors now provide their own branded Kubernetes Solutions (e.g. OpenShift).

	 Kubernetes exerts control over compute and storage resources by defining such resources as Objects, which can then be managed as such. The key objects are:

	 	<Pods> : the basic Kubernetes scheduling unit. A pod consists of one or more containers that are co-located on a single host machine and that can share resources. A pod can define a <volume> e.g. a local disk and expose it to the containers within the pod.  Each pod has a unique IP-address within the cluster by which other pods can address it. Containers within a pod can reference each other via 'localhost'.

		<Services> - A Kubernetes service is a set of pods that work together : e.g. as one tier in a multi-tier application. The set of pods that constitute a service are defined via a label-selector. A Service has assigned a stable IP address ( it persists across restarts, unlike pod iP-addresses which make get re-assigned on restart.) A service, by default, is not exposed outside of the cluster. To make it visible from outside, and so usable by clients, it needs to be explicitly exposed. Pods may be replicated underneath a service, and the Service will load balance between the pods.

		<Volumes> - Filesystems in a Container are volatile by default: if the container is restarted, the contents will be lost. A Kubernetes Volume provides persistent storage. These are mounted a specific mount points within the container and available to all containers within a pod.



* Documentation

		Documentation for OKD is available {{https://docs.okd.io/index.html}}




* Interactive Learning Portal

	There are a number of demonstration scenarios on the learn.openshift website. These provide a simulated environemnt that can be used to step through a number of scenarios throiugh which the OpenShift Platform can be used. I have stepped through some of those scenarios below, making notes as I have done so.

	The scenarios are available at {{https://learn.openshift.com/introduction}}.


** Getting Started with OpenShift for Developers

	 		Create a Project

			Add to Project
					Deploy Image
						openshiftroadshow/parksmap-katacoda:1.0.0
							Create

		Need to <create a route> in order for the deployed application to be accessible.

		Often applications will have backend services to support them.

		It is possible to deploy to RedHat direct from GitHub. This is done via the Source-to-Image tool (S2I).

		S2I is a tool for building reproducible Docker images. It takes an existing Docker image, injects 'Builder' sources code and assembles a new Docker image which incorporates both.

		Open-shift is S2I enbaled.


		If the backend is written in say Python, add python to the project from the systems catalog.

		Specify the name of the application and git-hub loctaion.


		Minishift

			Minishift is a completer OpenShift environemnt that can be run locally.

				{{http://www.openshift.org/vm}}


** Logging in to an OpenShift Cluster

	To logon via a specific user:

			oc login --username collaborator --password collaborator

			oc get projects

			oc whoami

	In order to make life easier in the early stages, the password to my kcrocombe RedHat account has been set as an environment variable. Consequentyl I should be able to logon as:

		oc login -u kcrocombe -p $OSPWD



* Deploying Application Components using the ODO tool

	<NB - The commands used in the demo version of odo do not seem to work with the latest version of the tool. In particular the syntax of the command used to create the application:>

		<<<$ odo app create wildwest>>>

	<does not seem to work any more. This is noted in the text below, and the new version of the command indicated (at least as best as I have been able to find out.)>

	<THIS NEEDS ATTENTION!>

	Documentation is available at {{https://openshiftdo.org/}}


** Introduction

	Odo (OpenShift Do) is a CLI tool to help build and deploy applications to OpneShift.

	I suspect it is a front-end to the sourceToImage tool (and possibly oc) : basically just providing a convenient way to perform the more typical packaging and deployment activities ( although I donlt know this for sure).

	Consider the following Scenario: an application consisting of:
		a back-end web service (developed say in spring)
		a front-end (developed say in node.js)

	We could deploy the application as 2 seperate components as described in what follows.

** Deploying the backend

	Logon to openshift

---
		odo login -u developer -p developer
			Login successful.

			You have one project on this server: "default"

			Using project "default".
---
	Create your project

---
		odo project create myproject
			OK  New project created and now using project : myproject
---
	Create an application:

	From the tutorial material, it seems that an application used to be created explicitly and then various components added to it, as in:

---

		$ odo app create wildwest
 				Creating application: wildwest in project: myproject
				Switched to application: wildwest in project: myproject
---
	<However, this does not seem to work with the version of odo that I have: <<odo app create>> no longer seems to be a valid commands. Instead the 'application', such that it is, is created as a bi-product of building a configuration. (see later on)>


	Create the Java Backend

	This is a java backend, so the necessary components will need to be available to it. This can be checked:

---
		$ odo catalog list components

				NAME        PROJECT       TAGS
				dotnet      openshift     2.0,latest
				httpd       openshift     2.4,latest
				java        openshift     8,8-1.5,8-1.6,latest
				nginx       openshift     1.10,1.12,1.8,latest
				nodejs      openshift     0.10,10,4,6,8,8-RHOAR,latest
				perl        openshift     5.16,5.20,5.24,5.26,latest
				php         openshift     5.5,5.6,7.0,7.1,latest
				python      openshift     2.7,3.3,3.4,3.5,3.6,latest
				ruby        openshift     2.0,2.2,2.3,2.4,2.5,latest
				wildfly     openshift     10.0,10.1,11.0,12.0,13.0,8.1,9.0,latest
---

	As you can see java is one of the services available within OpenShift.


	Build your application jar files in the usual way:

---
		mvn package
---

	Configure a container ready for deployment atop the Java Application Server. This will create a <component> named "Backend" of <component-type> java.  The process scans the source and target parts of the infrastructure and if all seems ok, creates a configureation (.yaml file) in a .odo subdirectory.

---
		odo create java backend --binary target/wildwest-1.0.jar --app wildwest
			Checking component
			Checking component version
			Creating component backend
---

	The Component container can then be deployed to the server. This seems to read the .yaml file previously created, and uploads it to the server:

---
		odo push

			Pushing changes to component: backend
			    Waiting for pod to start
			    Copying files to pod
			    Building component
			 OK  Changes successfully pushed to component: backend
---

		The 'application' can then be viewed. It think application is a bit of a false construct. I think an applicaiton is just a collection of objects carrying the same 'app=' tag.

---
	 	$ odo app list
			The project 'myproject' has the following applications:
			ACTIVE     NAME
			*          wildwest
---



** The Front-End component

	Likewise, create a application component for the frontend. Remember, Node.js is an interpreted language, so there is no compilation. Again a configuration file is written to .odo :

---
		odo create nodejs frontend
 			   Checking component
 			   Checking component version
 			   Creating component frontend
 			OK  Component 'frontend' was created and port 8080/TCP was opened
 			OK  Component 'frontend' is now set as active component
			To push source code to the component run 'odo push'
---
	..and deploy it

---
		odo push
			Pushing changes to component: frontend
		 	   Waiting for pod to start
		 	   Copying files to pod
		 	   Building component
		 	OK  Changes successfully pushed to component: frontend
---

	Create a Service Account for the backend to use.

---
		Console --> Dashboard
---


	Create a link between the front and the backend...

---
		odo link backend --component frontend --port 8080
 			OK  Component backend has been successfully linked to component frontend
---

 	Create a url in order to access the front end. This updates the .odo configuration file

---
		odo url create frontend
			Adding URL to component: frontend
 			OK  URL created for component: frontend

			frontend - http://frontend-wildwest-myproject.2886795334-80-cykoria05.environments.katacoda.com
---
		... and then push the configuration to the server
---
		odo push
---
	It is also possible to set up a background process that will monitor for changes to any of the source files, and redeploy them automatically should any one of them change. Its unclear whether this just works with interpreted files, or whether it will trigger maven type builds too...

---
		odo watch &
			[1] 32707
			$ Waiting for something to change in /root/frontend
---

	 Should you need to be reminded of what the URL is for your application:

---
	 	odo url list
			Found the following URLs for component frontend in application wildwest:
			NAME         URL                                                                                      PORT
			frontend     http://frontend-wildwest-myproject.2886795277-80-rhsummit1.environments.katacoda.com     8080
---

		Note that odo needs to be able to read its .odo configuration files for this, so you need to be in the correct directory.


* Deploying my own example

** A java Example

---
		odo create java app1 --binary target/gs-spring-boot-0.1.0.jar --app hello
		  Checking component
		  Checking component version
		  Creating java component with name app1
		  Initializing 'app1' component
		  Creating component app1
		  Successfully created component app1
		  Applying component settings to component: app1
		  The component app1 was updated successfully
		  Successfully updated component with name: app1
		  Pushing changes to component: app1 of type binary
		  Waiting for component to start
		  Copying files to component
		  Building component
		  Changes successfully pushed to component: app1

		odo push
		   Checking component
		   Checking component version
		   Creating java component with name app1
		   Initializing 'app1' component
		   Creating component component1
		   Successfully created component app1
		   Applying component settings to component: app1
		   The component app1 was updated successfully
		   Successfully updated component with name: app1
		   Pushing changes to component: app1 of type binary
		   Waiting for component to start
		   Copying files to component
		   Building component
		   Changes successfully pushed to component: app1

odo url create --component app1 --port 8080 --app kjc-application

odo push

odo url list --app kjc-application --component app1
Found the following URLs for component app1 in application kjc-application:
NAME                URL                                                                                          PORT
app1-8080     http://component1-8080-kjc-application-project2.1d35.starter-us-east-1.openshiftapps.com     8080

curl http://app1-8080-kjc-application-project2.1d35.starter-us-east-1.openshiftapps.com

	Greetings from Spring Boot!
---


** Deploying a Wildfly app1

		Created a wildfly project from the supplied demo (see wildfly stuff above)

---
		odo project create kjc-wildflyDemo2
		  New project created and now using project : kjc-wildfly

		odo create wildfly wildfly-component --binary ./wildfly-javaee7-webapp-archetype.war --app wildfly-app
		I0512 20:42:17.135144    2764 create.go:138] wildfly-javaee7-webapp-archetype.war
		   Checking component
		   Checking component version

		odo url create --port 8080 --app wildfly-app
   URL created for component: wildfly-component

		odo push
		  Checking component
	    Checking component version
	    Creating wildfly component with name wildfly-component
	    Initializing 'wildfly-component' component
	    Creating component wildfly-component
	    Successfully created component wildfly-component
	    Applying component settings to component: wildfly-component
	    Checking URL wildfly-component-8080
	    Successfully created URL for component: wildfly-component
	    http://wildfly-component-8080-wildfly-app-kjc-wildfly.1d35.starter-us-east-1.openshiftapps.com
	    The component wildfly-component was updated successfully
	    Successfully updated component with name: wildfly-component
	    Pushing changes to component: wildfly-component of type binary
	    Waiting for component to start
	    Copying files to component
	    Building component
	    Changes successfully pushed to component: wildfly-component

		odo url --list --app wildfly-app
		Found the following URLs for component wildfly-component in application wildfly-app:
		NAME                       URL                                                                                                PORT
		wildfly-component-8080     http://wildfly-component-8080-wildfly-app-kjc-wildfly.1d35.starter-us-east-1.openshiftapps.com     8080

		Content was available along:
			http://wildfly-component-8080-wildfly-app-kjc-wildfly.1d35.starter-us-east-1.openshiftapps.com/wildfly-javaee7-webapp-archetype

---

** Deployment of the standard GWT starter example.

	This is the starter poject that comes as part of the <modular-webapp> archetype (groupId: net.ltgt.gwt.Archetypes) which are recomended for use alongside the newer gwt-maven-plugin (groupID: net.ltgt.gwt.maven) referenced above.

	In theory, it structures the project into 3 sub-projects (client, shared, server).  At the moment, what is not clear to me is what parts of this need to be deployed where in a working system.

	So for a project test2 generated as follows:

---
	mvn archetype:generate \
		-DarchetypeGroupId=net.ltgt.gwt.archetypes \
		-DarchetypeVersion=LATEST \
		-DarchetypeArtifactId=modular-webapp \
		-DgroupId=uk.co.pegortech \
		-DartifactId=test2 \
		-Dversion=1.0-SNAPSHOT \
		-Dpackage=uk.co.pegortech.apps.newGWTplugin \
		-Dmodule=Module1 \
  	-Dmodule-short-name=mod1 \
		-DinteractiveMode=N
---

	...the system was built up in the usual maven way:

---
		mvn package
---

	This resulted in 2 .war packages and a jar package:

		* server - test2-server/target/test2-server-1.0-SNAPSHOT.war

		* client - test2-client/target/test2-client-1.0-SNAPSHOT.war

		* shared - test2-shared/target/test2-shared-1.0-SNAPSHOT.jar

	What was unclear to me was what and how each of these was to be deployed to wildfly. Just looking at the .war files it appeared that all the obviously required components where in there. So started by deploying this as follows:

---
	odo login -u kcrocombe -p $OSPWD

	odo project create gwt-project

	odo create wildfly backend --binary ./test1-server-1.0-SNAPSHOT.war --app gwt-test

	odo push

	odo url create --component backend --port 8080 --app gwt-test

	odo push

	odo url list
		NAME             URL                                                                                   PORT
		backend-8080     http://backend-8080-gwt-test-gwt-project.1d35.starter-us-east-1.openshiftapps.com     8080
---

	Browsing to this URL revealed a fully functioning app: in other words nothing needed to be done with the client or shared parts of the app. (...so, what's their purpose??).






* Downloading and Installing the Command Line Tools

	These are available from the Help Menu of the Application Console (they do not seem to be available from any more traditional Download page or Support Page).   This was downloaded as a tar bundle, and untarred to /apps/OpenShift/bin

	The contents is a single executable:

			oc

** Logging in

	I suspect that authentication to Redhat is via a OpenConnect ID. In order to login via the command line, we need to present a token that authenticates us as a valid user.

	In order to get hold of that token, plus the correct URL for your RedHat area you must logon to the console. At the top-right of the Application Console, under your username, there will be an option to capture the required details, inlcluding:

		The URL : https://api.starter-us-east-1.openshift.com
		The authentication token 2aT2XT-2mlvMU4xrxifRkVVIiRynbDuhR9_5marwNQU

	You can then login via the command line:

		oc login https://api.starter-us-east-1.openshift.com --token=2aT2XT-2mlvMU4xrxifRkVVIiRynbDuhR9_5marwNQU

	The token will typically last for 24 hrs or so, and then needs to be refereshed.

		You can view the token for your session

			oc whoami -t

	If you don't have a token and don't want to logon to the console for some reason, then a valid token can be dispensed here:

			{{https://api.starter-us-east-1.openshift.com/oauth/token/request]}}

	(I don't quiote understand why this doesn't prompt you for a username password: there must be some cookie somwhere?)


** Downloading and Installing the odo tools

	Not too sure about the status of this. According to its comments on GitHub, it may still be Beta tested only. However downloaded it anyway:

		{{https://github.com/openshift/odo}}

	This downloaded the source code as as a zip file.

	Unzipped it and ran the install.sh script.

	This installed odo to /usr/local/bin


====
* Deploying Applications from Images using the CLI (oc).

	When using OpenShift there are a number of different ways you can add an application. The main methods are:

		- Deploy an application from an existing Docker-formatted image.
		- Build and deploy from source code contained in a Git repository using a Source-to-Image builder.
		- Build and deploy from source code contained in a Git repository from a Dockerfile.

	What is described below is the first of these: deployment from an existing <Docker-formatted image>.


** Create a Project

	Within OpenShift, all resources ( except nodes) exist within the concept of a project. Projects have members, and roles and authorities over resources within that project. The names of resoources are unque within that project.

---
$ oc login -u developer -p developer
Login successful.

$ oc new-project myproject
Now using project "myproject" on server "https://172.17.0.45:8443".
---

** Create an application within the project.

	First, confirm that the name of the image to be deployed is valid. Images may exist in a number of places. The below assumes that the image is already located in a public repository (I believe these can be of three types:
			- docker images
			- stored Templates
			- Image streams
			)

---
oc new-app --search openshiftkatacoda/blog-django-py
Docker images (oc new-app --docker-image=<docker-image> [--code=<source>])

openshiftkatacoda/blog-django-py
 Registry: Docker Hub
 Tags:     latest
---

	Then create the application for real. The application exists really as a set of resource objects:
	 -An Imagestream (is)
	 -A Deployment Configurations (dc)
	 -A Replication Controller (rc)
	 -A Service (svc)
	 -A Pod (po)

	In creating the application, one each of these objects is created.

---
$ oc new-app openshiftkatacoda/blog-django-py
--> Found Docker image 14077cf (5 weeks old) from Docker Hub for "openshiftkatacoda/blog-django-py"

--> Creating resources ...
	 imagestream "blog-django-py" created
	 deploymentconfig "blog-django-py" created
	 service "blog-django-py" created
--> Success
	 Run 'oc status' to view your app.
---

	These objects can be viewed...

---
$ oc get all

NAME                DOCKER REPO                                  TAGS      UPDATED
is/blog-django-py   172.30.22.11:5000/myproject/blog-django-py   latest    22 minutes ago

NAME                REVISION   DESIRED   CURRENT   TRIGGERED BY
dc/blog-django-py   1          1         1         config,image(blog-django-py:latest)

NAME                  DESIRED   CURRENT   READY     AGE
rc/blog-django-py-1   1         1         1         22m

NAME                 CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
svc/blog-django-py   172.30.133.184   <none>        8080/TCP   22m

NAME                        READY     STATUS    RESTARTS   AGE
po/blog-django-py-1-6lczq   1/1       Running   0          22m
---

	To make the applcation accessible to external clients,we need to expose the service...

---
$ oc expose service/blog-django-py

route "blog-django-py" exposed
---

	...and the URL that can be used can be revealed

---
$ oc get route/blog-django-py

NAME             HOST/PORT                                                                  PATH      SERVICES         PORT  TERMINATION   WILDCARD
blog-django-py   blog-django-py-myproject.2886795315-80-simba02.environments.katacoda.com             blog-django-py   8080-tcp                None
---


** Openshift Routing

	An OpenShift URL exposes a service at a host name, e.g. www.example.com, so that external clients can reach it by name.  <<NEED TO FINISH THIS BIT OFF>>

** Importing Application Images

	Where an application image is to be deployed to multiple containers, possibly to provide the service over multiple nodes, then we need to deploy the same image stream several times.

	In these circumstances it makes sense to import the image first.

---
$ oc import-image openshiftkatacoda/blog-django-py --confirm
The import completed successfully.

Name:                   blog-django-py
Namespace:              default
Created:                Less than a second ago
Labels:                 <none>
Annotations:            openshift.io/image.dockerRepositoryCheck=2019-05-09T11:57:18Z
Docker Pull Spec:       172.30.203.78:5000/default/blog-django-py
Image Lookup:           local=false
Unique Images:          1
Tags:                   1
---

	This creates just the image stream Object

---
$ oc get all -o name
imagestreams/blog-django-py
---

	The application can then be deployed (as blog1) from the existing imagestream as follows:

---
$ oc new-app blog-django-py --name blog-1

--> Found image 14077cf (5 weeks old) in image stream "default/blog-django-py" under tag "latest" for "blog-django-py"

--> Creating resources ...
    deploymentconfig "blog-1" created
    service "blog-1" created
--> Success
---

	..and a second container deployed ( as blog-2)

---
$ oc new-app blog-django-py --name blog-2

--> Found image 14077cf (5 weeks old) in image stream "default/blog-django-py" under tag "latest" for "blog-django-py"

--> Creating resources ...
    deploymentconfig "blog-2" created
    service "blog-1" created
--> Success
---

** Deleting an Application

	As alluded to above, an application exists only really as a collection of resource. However, we can make use of labels in order to identify all objects that belong to an application. We can make use of that label in the delete
	command in order to remove all resource carrying that label.

---
$ oc delete all --selector app=blog-django-py
imagestream "blog-django-py" deleted
deploymentconfig "blog-django-py" deleted
route "blog-django-py" deleted
service "blog-django-py" deleted
pod "blog-django-py-1-vrq5t" deleted

$ oc get all -o name
---
=====

* Deploying Applications from Source.

	This is the second of out three ways of deploying an application to openshift. Here we shall deploy from source code held in a Git Repository using Source-to-Image Builder. This relies on a Build Configuration : i.e. an object that informs the infrastrucure as to how executable objects should be constructed.

	There are several options for this, but most will either be:
		a Docker build
		a Source-To-Image build (S2I)

	This demo illustrates the S2I option.


	The following will deploy an application from the github repository {{https://github.com/openshift-katacoda/blog-django-py}}. It will be deployed using the S2I builder for the latest version opf Pythn available on the platform.

	The application will use the name "blog" rather then the defualt.

---
	$ oc new-app python:latest~https://github.com/openshift-katacoda/blog-django-py --name blog
--> Found image 2db34dd (5 weeks old) in image stream "openshift/python" under tag "latest" for "python:latest"

--> Creating resources ...
    imagestream "blog" created
    buildconfig "blog" created
    deploymentconfig "blog" created
    service "blog" created
--> Success
    Build scheduled, use 'oc logs -f bc/blog' to track its progress.
    Run 'oc status' to view your app.
---

	The build of the application will proceed in the background. The progress can be monitored via

---
	oc logs -f bc/blog
---
	As usual, the end-point then has to be exposed to the external world

---
$ oc expose service/blog
route "blog" exposed

$ oc get route/blog
NAME      HOST/PORT                                                      PATH      SERVICES   PORT       TERMINATION   WILDCARD
blog      blog-default.2886795448-80-simba02.environments.katacoda.com             blog       8080-tcp                 None
---

	Note that once the infrastructure knows how to build an application, rebuilds can be triggered as follows

---
$ oc start-build blog
build "blog-2" started

---

* Installing Minishift

	Minishift is a tool that help you run OpenShift on your local machine inside a Virtual Machine.

	Minishift documentation is {{{https://docs.okd.io/latest/minishift/index.html} here}}.

---
brew install docker-machine-driver-xhyve

sudo chown root:wheel /usr/local/opt/docker-machine-driver-xhyve/bin/docker-machine-driver-xhyve

sudo chmod u+s /usr/local/opt/docker-machine-driver-xhyve/bin/docker-machine-driver-xhyve

brew cask install minishift
---


MORE STUFF TO GO IN HERE...


===============

======

{Technology Glossary}

	[Ruby] - A object orientated, interpretated scripting language : quite powerful
	[Rails] - A Ruby-based Rapid Application Development tool, well suited to CRUD/database/web Applications

	[Groovy] - Java-like language (and infact compiles to java byte code), but can be interpreted. Has features similar to Perl, Python, Ruby, Smalltalk. Supposedly simpler than Java.
	[Grails] - A Groovy based WebFramework ( uses Spring)
	[Gradle] - A popular build tool bases on Groovy

	[Spring Roo] - Springs Rapid Application Development Tool.
